# ğŸ“¦ Drone Delivery Analytics â€“ Spark Batch Processing Pipeline

## ğŸ§­ Contexte

Dans le cadre de la gestion d'une flotte de drones de livraison, il est crucial dâ€™analyser les journaux de vol pour dÃ©tecter des anomalies, optimiser les performances, surveiller la consommation Ã©nergÃ©tique, et garantir la fiabilitÃ© des trajets. Les drones envoient pÃ©riodiquement (toutes les 30 secondes) des logs comprenant leur position, Ã©tat de batterie, charge transportÃ©e et statut opÃ©rationnel.

---
## ğŸ¯ Contexte du problÃ¨me
Le systÃ¨me collecte un volume important de donnÃ©es en continu. Or, les traitements analytiques classiques deviennent coÃ»teux et lents Ã  mesure que la volumÃ©trie augmente.
Ton job Spark lit 1,5 To de donnÃ©es GPS sur 7 jours pour calculer des statistiques de vol par drone (distance, vitesse, consommation, etc.).
Mais :

- ğŸŒ Il est trÃ¨s lent (> 2h)

- ğŸ”„ Il fait beaucoup de shuffle

- âš ï¸ Les CPU sont dÃ©sÃ©quilibrÃ©es entre les workers

Deux principaux dÃ©fis techniques sont identifiÃ©s :

- Le **skew de donnÃ©es** causÃ© par des drones plus actifs que d'autres, gÃ©nÃ©rant des dÃ©sÃ©quilibres de partitionnement.

- Le besoin d'une **architecture scalable et performante** pour calculer les indicateurs clÃ©s comme :
  - DurÃ©e moyenne de vol
  - Distance moyenne parcourue
  - Vitesse moyenne
  - Consommation moyenne de batterie

---
## ğŸ”§ Tech Stack

| Stage                      | Technology                          |
|---------------------------|--------------------------------------|
| Data Ingestion            | fichier csv|
| Data Processing           | Apache Spark                         |
| Storage                   | Google BigQuery                      |
| Data Transformation       | dbt Cloud                            |
| Data Visualization        | Looker Studio (or Power BI)          |
| Orchestration             | Apache Airflow (Dockerized)          |
| Containerization          | Docker + Docker Compose              |

---


## ğŸ› ï¸ MÃ©thodologie et Architecture

### ğŸ” Pipeline de Traitement

1. **Chargement des logs** (au format Parquet pour optimiser la lecture).
2. **Filtrage des statuts `in_flight`**.
3. **Identification des vols distincts** (sÃ©paration par intervalle de 30s ou plus).
4. **Calculs par vol** :
   - Temps de vol
   - Distance (formule de Haversine)
   - Batterie consommÃ©e
5. **AgrÃ©gation par drone** :
   - Moyennes globales des indicateurs

### âš–ï¸ Gestion du Skew (Salting)

Pour Ã©viter que Spark nâ€™exÃ©cute des tÃ¢ches dÃ©sÃ©quilibrÃ©es Ã  cause de drones trÃ¨s prÃ©sents :
- Un seuil est dÃ©fini (ex : 634 logs)
- Les drones dÃ©passant ce seuil sont "saltÃ©s" via une colonne alÃ©atoire
- Le `repartition` se fait ensuite sur `drone_id` + `salt` pour Ã©quilibrer le traitement entre workers

### ğŸ’¡ Optimisations appliquÃ©es

- **Format Parquet** pour accÃ©lÃ©rer les I/O
- **Window Functions** pour dÃ©tecter les segments de vol
- **Calculs vectoriels** (radians, sin, cos) directement dans Spark SQL
- **Utilisation de UDFs Ã©vitÃ©e** pour maximiser le parallÃ©lisme natif Spark
- **Repartition stratÃ©gique** avant les `groupBy`

---

## ğŸ“ˆ RÃ©sultats obtenus

- âœ… Calcul correct et rapide des mÃ©triques clÃ©s sur un dataset volumineux
- âœ… Bonne scalabilitÃ© observÃ©e grÃ¢ce au format parquet et au salting
- âœ… Pipeline entiÃ¨rement Ã©crit en **PySpark** avec une approche modulaire (class-based)
- âœ… Tests unitaires mis en place sur le salting pour valider la logique
- âœ… Une table BigQuery contenant les **statistiques de vol moyennes par drone** :
  - `avg_flight_duration` (secondes),
  - `avg_battery_consumption` (%),
  - `avg_distance` (km),
  - `avg_speed` (km/h).

---

## ğŸ“¤ Ã‰tapes suivantes (non implÃ©mentÃ©es dans ce repo)

- IntÃ©gration avec **Apache Airflow** pour lâ€™orchestration
- Surveillance des mÃ©triques via un tableau de bord (Grafana, Looker, PowerBI...)

---

## ğŸ“ Arborescence du projet

```bash
.
â”œâ”€â”€ .devcontainer/
â”‚   â””â”€â”€ decontainer.json
    â””â”€â”€ docker-compose.yml  
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ tasks/
        â””â”€â”€ BigQuery/
â”‚           â””â”€â”€ create_bigquery_connection_task.py
            â””â”€â”€ load_to_bigquery_table_task.py
â”‚       â””â”€â”€ spark/
â”‚           â””â”€â”€ calculate_drone_flight_metrics.py
    â”œâ”€â”€ data/
â”‚         â””â”€â”€ drone_flight_logs_large.csv
â”œâ”€â”€ keys/
â”‚   â””â”€â”€ real-time-traffic-pipeline-xxx.json
â”œâ”€â”€ libs/
â”‚   â””â”€â”€ gcs-connector-hadoop3-latest.jar
    â””â”€â”€ spark-bigquery-with-dependencies_2.12-0.32.2.jar
â”œâ”€â”€ test/
â”‚   â””â”€â”€ apply_salting_test.py
â”œâ”€â”€ README.md
